    parser.add_argument('--adjacent_range', nargs='+', type=int, required=True,
                        help='interval range for a pair of video frames')
    parser.add_argument('--image_downsampling', type=float, default=4.0,
                        help='input image downsampling rate for training acceleration')
    parser.add_argument('--network_downsampling', type=int, default=64,
                        help='network downsampling rate')
    parser.add_argument('--input_size', nargs='+', type=int, required=True,
                        help='input size')
    parser.add_argument('--num_workers', type=int, default=8, help='number of workers for data loader')
    parser.add_argument('--num_pre_workers', type=int, default=8,
                        help='number of pre-processing workers for data loader')
    parser.add_argument('--inlier_percentage', type=float, default=0.998,
                        help='percentage of inliers of SfM point clouds (for pruning extreme outliers)')
    parser.add_argument('--testing_patient_id', nargs='+', type=int, required=True, help='id of the testing patient')
    parser.add_argument('--load_intermediate_data', action='store_true',
                        help='whether or not to load intermediate data')
    parser.add_argument('--visibility_overlap', type=int, default=20, help='overlap of point visibility information')
    parser.add_argument('--display_architecture', action='store_true', help='display the network architecture')
    parser.add_argument('--trained_model_path', type=str, default=None, help='path to the trained model')
    parser.add_argument('--training_data_root', type=str, required=True, help='path to the sfm training data')
    parser.add_argument('--log_root', type=str, required=True, help='root of logging')
    parser.add_argument('--feature_length', type=int, default=128, help='output channel dimension of network')
    parser.add_argument('--filter_growth_rate', type=int, default=12, help='filter growth rate of network')
    parser.add_argument('--rr_weight', type=float, default=1.0, help='weight of relative response loss')
    parser.add_argument('--keypoints_per_iter', type=int, default=200, help='number of keypoints per iteration')
    parser.add_argument('--gpu_id', type=int, default=0, help='id of selected GPU')

--adjacent_range
1 50
--image_downsampling
4.0
--network_downsampling
64
--input_size
256 320
--num_workers
4
--num_pre_workers
4
--inlier_percentage
0.99
--testing_patient_id
1
--load_intermediate_data
--visibility_overlap
20
--display_architecture
--trained_model_path
"/home/xliu89/tmp_ramfs/DenseDescriptorLearning-Pytorch/Train/dense_descriptor_train_3_1_13_18/checkpoint_model_epoch_0_0.7674000118970872_0.832900013923645_0.904550008058548.pt"
--testing_data_root
"/home/xliu89/tmp_ramfs/DenseDescriptorLearning-Pytorch/example_training_data_root"
--log_root
"/home/xliu89/tmp_ramfs/DenseDescriptorLearning-Pytorch/Train"
--feature_length
256
--filter_growth_rate
10
--keypoints_per_iter
3000
--gpu_id
0

