    parser.add_argument('--adjacent_range', nargs='+', type=int, required=True,
                        help='interval range for a pair of video frames')
    parser.add_argument('--image_downsampling', type=float, default=4.0,
                        help='input image downsampling rate for training acceleration')
    parser.add_argument('--network_downsampling', type=int, default=64,
                        help='network downsampling rate')
    parser.add_argument('--input_size', nargs='+', type=int, required=True,
                        help='input size')
    parser.add_argument('--id_range', nargs='+', type=int, required=True,
                        help='id range for the training, validation, and testing dataset')
    parser.add_argument('--batch_size', type=int, default=8, help='batch size of input samples')
    parser.add_argument('--num_workers', type=int, default=8, help='number of workers for data loader')
    parser.add_argument('--num_pre_workers', type=int, default=8,
                        help='number of pre-processing workers for data loader')
    parser.add_argument('--lr_range', nargs='+', type=float, required=True,
                        help='lower and upper bound learning rate for cyclic lr')
    parser.add_argument('--inlier_percentage', type=float, default=0.998,
                        help='percentage of inliers of SfM point clouds (for pruning extreme outliers)')
    parser.add_argument('--display_interval', type=int, default=10, help='iteration interval of image display')
    parser.add_argument('--validation_interval', type=int, default=1, help='iteration interval for validation')
    parser.add_argument('--training_patient_id', nargs='+', type=int, required=True,
                        help='id of the training patient')
    parser.add_argument('--validation_patient_id', nargs='+', type=int, required=True,
                        help='id of the validation patient')
    parser.add_argument('--testing_patient_id', nargs='+', type=int, required=True, help='id of the testing patient')
    parser.add_argument('--load_intermediate_data', action='store_true',
                        help='whether or not to load intermediate data')
    parser.add_argument('--load_trained_model', action='store_true', help='whether or not to load trained model')
    parser.add_argument('--num_epoch', type=int, required=True, help='number of epochs in total')
    parser.add_argument('--num_iter', type=int, required=True, help='maximum number of iterations per epoch')
    parser.add_argument('--heatmap_sigma', type=float, default=5.0,
                        help='sigma of heatmap for ground truth visualization')
    parser.add_argument('--visibility_overlap', type=int, default=20, help='overlap of point visibility information')
    parser.add_argument('--display_architecture', action='store_true', help='display the network architecture')
    parser.add_argument('--trained_model_path', type=str, default=None, help='path to the trained model')
    parser.add_argument('--training_data_root', type=str, required=True, help='path to the sfm training data')
    parser.add_argument('--sampling_size', type=int, default=10,
                        help='number of positive sample pairs per iteration')
    parser.add_argument('--log_root', type=str, required=True, help='root of logging')
    parser.add_argument('--feature_length', type=int, default=128, help='output channel dimension of network')
    parser.add_argument('--filter_growth_rate', type=int, default=12, help='filter growth rate of network')
    parser.add_argument('--matching_scale', type=float, default=20.0, help='scale for soft thresholding')
    parser.add_argument('--matching_threshold', type=float, default=0.9, help='threshold for soft thresholding')
    parser.add_argument('--rr_weight', type=float, default=1.0, help='weight of relative response loss')
    parser.add_argument('--cross_check_distance', type=float, default=5.0, help='cross check distance for '
                                                                                'pair-wise feature matching pruning')


--adjacent_range
1 50
--image_downsampling
4.0
--network_downsampling
64
--input_size
256 320
--id_range
1
--batch_size
4
--num_workers
4
--num_pre_workers
4
--lr_range
1.0e-4 1.0e-3
--inlier_percentage
0.99
--display_interval
20
--validation_interval
1
--training_patient_id
1
--validation_patient_id
1
--testing_patient_id
1
--load_intermediate_data
--num_epoch
50
--num_iter
1000
--heatmap_sigma
5.0
--visibility_overlap
20
--display_architecture
--training_data_root
"/home/xliu89/tmp_ramfs/DenseDescriptorLearning-Pytorch/example_training_data_root"
--sampling_size
10
--log_root
"/home/xliu89/tmp_ramfs/DenseDescriptorLearning-Pytorch/Train"
--feature_length
256
--filter_growth_rate
10
--matching_scale
20.0
--matching_threshold
0.9
--rr_weight
1.0
--cross_check_distance
5.0
